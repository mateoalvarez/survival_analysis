% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% The "real" document content comes below...

\title{Survival Analysis with Apache Spark and Apache SystemML on Stackexchange}
\author{Mateo √Ålvarez Calvo}
%\date{} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed

\begin{document}

\maketitle
% \makesummary


\section{Introduction \& main goals}

Many studies have been done over the Stackexchange community [such as], one of the biggest Q\&A sites in the world. The present is yet another study over the data of the famous site, but in this case, the study has two particularities, the use of Apache Spark with the library of Apache SystemML for the processing in a parallel environment, and the use of Survival Analysis to analyze the impact of the variables in the time an answer is accepted for each question, the "survival of each question" in the community.

\subsection{Main technologies}

As one of the biggest Q\&A communities, Stackexchange has large amount of data of each interaction.
Stackexchange is separated in several communities, regarding diferent topics. These communities can be small, as [] or really big, as Stackoverflow, the developers community. This particularity makes necessary the use technologies prepared to process large amounts of data, in the later case.

Among the available big data technologies, the

For this purpose, Apache Spark, the latest distributed open-source processing technology, has been chosen to parallelize the operations on the data.

Spark ML is the machine learning library of spark, which contains lots of algorithms. It also includes some Survival Analysis algorithms, but just for parametric modelling. This gives an excuse to use the recently adopted by the Apache Foundation SystemML, a machine learning library developed by IBM, which has non, semi and parametric algorithms for survival analysis.


\subsubsection{Apache Spark}

Apache Spark is a distributed processing technology developed in Scala by Databricks that represents the next step of Apache Hadoop, including the best parts of it, such as the Hadoop File System, but under a complete new paradigm that allows operations diferent from the famous map-reduce, using RAM as storage for results rather than writting to disk and lazy and optimized execution of tasks, to mention some of the main features.

\subsubsection{Apache SystemML}

Recently included in the Apache Foundation Incubating  program, Apache SystemML is a machine learning library that works over distributed frameworks, Spark or Hadoop, written in a self made language, Distributed Machine Learning (dml) and with a python, scala or R like syntaxis API.

This library provides many distributed implementations of important algorithms as well as a syntaxis to create new algorithms in a distributed mode.

\subsection{The Stackexchange data}

Stackexchange facilitates raw {partially processed?} data from the communities database every once in a while {or every three months?} for data scientists and people in general to download and analyze. The data is available in a torrent file and each package has about 35 - 40 GB of compressed information.

This compressed file has data from different communities for a certain period of time. In our case, the analysis is done over Scyfy community, wich is a median size community for science-fiction Q\&A.

\subsection{Main Objectives}

For this study several objectives have been proposed:

\begin{itemize}

  \item Use Spark to make the data cleaning to create a script for further research on the Stackexchange site.

  \item Verify SystemML integration with Spark for further research and scalability.

  \item Use SystemML survival analysis algorithms to analize Stackexchange's data and obtain conclussions on the main variables affecting the fast resolution of questions.

\end{itemize}

\section{Technologies}

The downloaded data from Stackexchange for the analysis [weights?] 40 GB, wich is enough ammount [size] to consider distributed processing.

\subsection{Apache Spark}

The latest distributed processing technology for data processing is Apache Spark, born in [2015] in [Ucla?], wich is the precursor of the well known processing framework Apache Hadoop, with all it's ecosystem.

Comparing to Hadoop, Spark is able to speedup calculations, with a higher variety of operations, not limited to Map-Reduce, preserving the fault tolerance and [].

\subsubsection{Apache Spark Structure}




\subsection{Apache SystemML}

Developed by IBM, Apache SystemML is the [precursor] of Spark ML (MLLib), the machine learning libraries of Spark.
SystemML is coded in a self-made programming language, Distributed Machine Learning (DML) and it can be used from Spark or Hadoop in a [submit-like execution or in a interactive execution, the one it has been used in this study]

\subsubsection{SystemML Structure}



\subsection{Reproducible research with Python, Scala and Jupyter}



\section{Infrastructure and resources}

\subsection{Architecture scheme

\subsection{Configuration}

\subsection{Workflow}

\section{Results}

\subsection{Used data}

\subsection{Kaplan-Meier model}

\subsection{Cox Proportional Hazards Model}

\section{Conclussions}

\subsection{Most important results}

\subsection{Lessons learnt}



\end{document}
